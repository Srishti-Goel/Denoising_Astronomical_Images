# -*- coding: utf-8 -*-
"""data_handeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ToWsgJ13yXhfoHPX1pnxjDQoFPpOrern
"""

import pandas as pd
import io
dftrain = pd.read_csv('train_data.txt',header=None)

print(dftrain)

from astroquery.mast import Catalogs
from astroquery.vizier import Vizier
from astroquery.mast import Observations
import urllib.request
import os

filter_wide = ["F555W","F606W"]
for f in filter_wide:
    obsTable = Observations.query_criteria(calib_level= 3, dataproduct_type = 'image',
                                               obs_collection = ["HLA"],
                                        instrument_name = ["WFC3/UVIS"], filters = [f])

for url in obsTable['dataURL']:
  if isinstance(url, type(obsTable[4]['dataURL'])):
    if url[-5:] == str(".fits"):
      print(url)

os.makedirs("image")

for i in range (dftrain.shape[0]):
  satr= str(dftrain.loc[i].at[0])
  for url in obsTable['dataURL']:
    if isinstance(url, type(obsTable[3]['dataURL'])):
      if url[-5:] == str(".fits"):
        stry=url[50:78]
        if stry == str(satr):
                file = "image/" + stry
                urllib.request.urlretrieve(url,file)

from astropy.io import fits

from astropy.wcs import WCS
import matplotlib.pyplot as plt

os.makedirs("png")

for i in range (dftrain.shape[0]):
  satr= str(dftrain.loc[i].at[0])
  for url in obsTable['dataURL']:
    if isinstance(url, type(obsTable[3]['dataURL'])):
      if url[-5:] == str(".fits"):
        stry=url[50:78]
        if stry == str(satr):
          path= os.path.join('image/' + stry)
          gals = fits.open(path)
          with fits.open(path) as hdu:
            data = hdu[1].data
            wcs = WCS(hdu[1].header)
            cutout = data[:,:]
            plt.subplot(projection=wcs)
            plt.imshow(cutout, vmin=0, vmax=0.1)
            plt.grid(color='white', ls=':', alpha=0.7)
            file = "png/" + stry
            plt.savefig(file)

from PIL import Image

import os

path, dirs, files = next(os.walk("png"))
file_count = len(files)

print(file_count)

for url in obsTable['dataURL']:
    if isinstance(url, type(obsTable[3]['dataURL'])):
      if url[-5:] == str(".fits"):
        stry=url[50:78]
        if stry == str(satr):
          pata= os.path.join('png/' + stry + '.png')
          imag=Image.open(pata)
          imag.show()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
for url in obsTable['dataURL']:
    if isinstance(url, type(obsTable[3]['dataURL'])):
      if url[-5:] == str(".fits"):
        stry=url[50:78]
        if stry == str(satr):
          pata= os.path.join('png/' + stry + '.png')
          img = mpimg.imread(pata)
          imgplot = plt.imshow(img)
          plt.show()
          plt.savefig(file)

path= os.path.join('png/hst_11684_01_wfc3_uvis_f606w.png')
img = mpimg.imread(path)
imgplot = plt.imshow(img)
plt.show()

url='https://hla.stsci.edu/cgi-bin/getdata.cgi?dataset=hst_11924_02_wfc3_uvis_f606w_drz.fits'

t= urllib.request.urlretrieve(url)

gals = fits.open(url)
with fits.open(url) as hdu:
            data = hdu[1].data
            wcs = WCS(hdu[1].header)
            cutout = data[3665:5113,2656:3827]
            plt.subplot(projection=wcs)
            plt.imshow(cutout, vmin=0, vmax=0.1)
            plt.grid(color='white', ls=':', alpha=0.7)
            plt.savefig('1.png')

import tensorflow as tf
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Input
import numpy as np



n_epochs = 2


#----------TRANSFORMING IMAGES------------
def noise_adder(data, ratio, exposure_time, patch_noise=False, xx=None, yy=None, ps=None, DN=True, RON=True, PSN=True, ron=1, dk=1, return_noisy=False):
  #image_data = Image(name)
  if patch_noise:
   data = data[xx:xx+ps, yy:yy+ps]
  width, height = data.shape
  img = data*exposure_time

  dark_noise = np.random.normal(0, np.sqrt(dk * exposure_time/(3600*ratio)), (width, height))
  read_out_noise = np.random.normal(0, ron, (width, height))
  photon_shot_noise = np.random.poisson(np.abs(img/ratio))

  total_noise = (dark_noise if DN else 0) + (read_out_noise if RON else 0) + (photon_shot_noise if PSN else 0)
  total_noise = total_noise / (exposure_time / ratio)
  total_noise = np.where(data == 0.00, 0.00, total_noise)
  
  if return_noisy:
    return total_noise

noisy_image = noise_adder(data, 2, 100, return_noisy=True)
print(noisy_image.shape)
cutout= noisy_image[3665:5113,2656:3827]
wcs = WCS(hdu[1].header)
plt.subplot(projection=wcs)
plt.imshow(cutout, vmin=0, vmax=0.1)
plt.grid(color='white', ls=':', alpha=0.7)
plt.savefig('noise.png')
#model.compile(optimizer=optimizer, loss=loss_func, metrics=metric )
#model_history = model.fit(train_dataset, n_epochs)

path= os.path.join('1.png')
img = mpimg.imread(path)
imgplot = plt.imshow(img)
plt.show()

path= os.path.join('noise.png')
img = mpimg.imread(path)
imgplot = plt.imshow(img)
plt.show()

activation_type = 'relu'
n_filters_in_input = 1
batch_size=4
optimizer = 'adam'
loss_func = tf.keras.losses.MeanSquaredError(reduction="auto", name="mean_squared_error")
metric = ['accuracy']


def conv_block(input=None, n_filters=32, dropout_prob=0, max_pooling=True):
  
  print("Incoming", type(input))
  conv = Conv2D(filters=n_filters, 
                kernel_size=2, 
                activation=activation_type, 
                padding='same')(input)
  print("Going once", type(conv))
  conv = Conv2D(filters=n_filters, 
                kernel_size=3, 
                activation=activation_type, 
                padding='same')(conv)

  if dropout_prob > 0:
    conv = tf.keras.layers.Dropout(dropout_prob)(conv)

  print("Going twice", type(conv))
    
  if max_pooling:
    next_layer = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2, padding='valid')(conv)
  else:
    next_layer = conv
  
  skip_connection = conv

  return next_layer, skip_connection

def upsampling_block(prev_layer, skip_layer, n_filters=32):
  up = tf.keras.layers.Conv2DTranspose(
      n_filters,
      (3,3), #kernel size
      (2,2), #strides
      'same' #padding
  )(prev_layer)

  merge = concatenate([up, skip_layer], axis=3)
  conv = Conv2D(n_filters, kernel_size=3, activation=activation_type, padding='same')(merge)
  conv = Conv2D(n_filters, kernel_size=3, activation=activation_type, padding='same')(conv)

  return conv

def unet_model(input_size=( cutout.shape), n_filters=32):
  print(type(Input((1,2))))
  inputs = Input(input_size)

  cblock1 = conv_block(inputs, n_filters)
  cblock2 = conv_block(cblock1[0], 2 * n_filters)
  cblock3 = conv_block(cblock2[0], 4 * n_filters)
  cblock4 = conv_block(cblock3[0], 8 * n_filters)
  cblock5 = conv_block(cblock4[0], 16 * n_filters, max_pooling=False)
  ublock6 = upsampling_block(cblock5[0], cblock4[1], 8 * n_filters)
  ublock7 = upsampling_block(ublock6, cblock3[1], 4 * n_filters)
  ublock8 = upsampling_block(ublock7, cblock2[1], 2 * n_filters)
  ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)
  conv9 = Conv2D(n_filters,
                 3,
                 activation=activation_type,
                 padding='same',
                 kernel_initializer='he_normal')(ublock9)
  conv10 = Conv2D(n_filters_in_input, 1 , padding='same')(conv9)
wcs = WCS(hdu[1].header)
plt.subplot(projection=wcs)
plt.imshow(conv10 , vmin=0, vmax=0.1)
plt.grid(color='white', ls=':', alpha=0.7)
plt.savefig('2.png')

  #model = tf.keras.Model(inputs=inputs, outputs=conv10)

  #return model

#model = unet_model()
#model.summary()

